{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MonReader (Computer Vision)\n",
    "\n",
    "#### Background:\n",
    "\n",
    "##### MonReader is a new mobile document digitization experience for the blind, for researchers and for everyone else in need for fully automatic, highly fast and high-quality document scanning in bulk. It is composed of a mobile app and all the user needs to do is flip pages and everything is handled by MonReader: it detects page flips from low-resolution camera preview and takes a high-resolution picture of the document, recognizing its corners and crops it accordingly, and it dewarps the cropped document to obtain a bird's eye view, sharpens the contrast between the text and the background and finally recognizes the text with formatting kept intact, being further corrected by MonReader's ML powered redactor.\n",
    "\n",
    "#### Data Description:\n",
    "\n",
    "##### We collected page flipping video from smart phones and labelled them as flipping and not flipping.\n",
    "\n",
    "##### We clipped the videos as short videos and labelled them as flipping or not flipping. The extracted frames are then saved to disk in a sequential order with the following naming structure: VideoID_FrameNu\n",
    "\n",
    "#### Goal(s):\n",
    "\n",
    "##### Predict if the page is being flipped using a single image.\n",
    "\n",
    "#### Success Metrics:\n",
    "\n",
    "##### Evaluate model performance based on F1 score, the higher the better.\n",
    "\n",
    "#### Bonus(es):\n",
    "\n",
    "##### Predict if a given sequence of images contains an action of flipping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch # PyTorch package\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import *\n",
    "from torchsummary import summary\n",
    "from pytorchtools import EarlyStopping\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import splitfolders\n",
    "import os\n",
    "import re\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.use(\"Agg\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#importing functions and parameters files\n",
    "from functions import Net, file_screener\n",
    "from params import bs, num_epochs, device, patience, lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's split the training folder into training and validation folders, load and transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only run one time\n",
    "#splitfolders.ratio(\"images/training\", output=\"training-validation\",\n",
    "#    seed=1337, ratio=(.8, .2), group_prefix=None, move=False) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(1080),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flip', 'notflip']\n"
     ]
    }
   ],
   "source": [
    "#loading the data\n",
    "train_data = datasets.ImageFolder('training-validation/train', transform = transform)\n",
    "val_data = datasets.ImageFolder('training-validation/val', transform = transform)\n",
    "test_data = datasets.ImageFolder('images/testing', transform = transform)\n",
    "print(train_data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can see that there are two classes, flip and notflip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the train, validation, and test data loaders\n",
    "trainloader = torch.utils.data.DataLoader(train_data, shuffle = True, batch_size = bs)\n",
    "valloader = torch.utils.data.DataLoader(val_data, batch_size = bs)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size = bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate steps per epoch for training and validation set\n",
    "trainSteps = len(trainloader.dataset) // bs\n",
    "valSteps = len(valloader.dataset) // bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train input size: torch.Size([16, 3, 224, 224]), train class size: torch.Size([16])\n",
      "val input size: torch.Size([16, 3, 224, 224]), val class size: torch.Size([16])\n",
      "test input size: torch.Size([16, 3, 224, 224]), test class size: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "train_inputs, train_classes = next(iter(trainloader))\n",
    "print(f'train input size: {train_inputs.shape}, train class size: {train_classes.shape}')\n",
    "val_inputs, val_classes = next(iter(valloader))\n",
    "print(f'val input size: {val_inputs.shape}, val class size: {val_classes.shape}')\n",
    "test_inputs, test_classes = next(iter(testloader))\n",
    "print(f'test input size: {test_inputs.shape}, test class size: {test_classes.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the images\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(train_inputs[i].permute(1, 2, 0))\n",
    "    plt.title([train_data.classes[train_classes[i]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the network...\n"
     ]
    }
   ],
   "source": [
    "# measure how long training is going to take\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We created a CNN model to use for image prediction using the Binary Cross Entropy as our loss function and Adam as our optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling our model\n",
    "model = Net()\n",
    "\n",
    "# initialize our optimizer and loss function\n",
    "# specify loss function\n",
    "lossFn = nn.BCELoss() \n",
    "# specify optimizer\n",
    "opt = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We are implementing early stopping while training the model in order to prevent overfitting. Early stopping keeps track of the validation loss and is used to stop the training, if the loss stops decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model using early stopping\n",
    "def train_model(model, bs, patience, num_epochs):\n",
    "\n",
    "\t# to store training history\n",
    "\ttrain_loss = []\n",
    "\ttrain_acc = []\n",
    "\tval_loss = []\n",
    "\tval_acc = []\n",
    "\n",
    "\t# initialize the early_stopping object\n",
    "\tearly_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "\t#training loop\n",
    "\t# loop over our epochs\n",
    "\tfor e in range(0, num_epochs):\n",
    "\t\t# set the model in training mode\n",
    "\t\tmodel.train()\n",
    "\t\t# initialize the total training and validation loss\n",
    "\t\ttotalTrainLoss = 0\n",
    "\t\ttotalValLoss = 0\n",
    "\t\t# initialize the number of correct predictions in the training\n",
    "\t\t# and validation step\n",
    "\t\ttrainCorrect = 0\n",
    "\t\tvalCorrect = 0\n",
    "\t\t# loop over the training set\n",
    "\t\tfor (x, y) in trainloader:\n",
    "\t\t\t# send the input to the device\n",
    "\t\t\t(x, y) = (x.to(device), y.to(device))\n",
    "\t\t\t# clear the gradients of all optimized variables\n",
    "\t\t\topt.zero_grad()\n",
    "\t\t\t# perform a forward pass and calculate the training loss\n",
    "\t\t\tpred = model(x)\n",
    "\t\t\tloss = lossFn(pred, y.type(torch.float32).unsqueeze(1))\n",
    "\t\t\t# zero out the gradients, perform the backpropagation step,\n",
    "\t\t\t# and update the weights\n",
    "\t\t\tloss.backward()\n",
    "\t\t\topt.step()\n",
    "\t\t\t# add the loss to the total training loss so far and\n",
    "\t\t\t# calculate the number of correct predictions\n",
    "\t\t\ttotalTrainLoss += loss\n",
    "\t\t\ttrainCorrect += (torch.round(pred) == y).type(torch.float).mean().item()\n",
    "\n",
    "\t\t# Zeroing gradient, performing backpropagation, updating weights of the model\n",
    "\t\t# set the model in evaluation mode\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tmodel.eval() # prep model for evaluation\n",
    "\t\t\t# loop over the validation set\n",
    "\t\t\tfor (x, y) in valloader:\n",
    "\t\t\t\t# send the input to the device\n",
    "\t\t\t\t(x, y) = (x.to(device), y.to(device))\n",
    "\t\t\t\t# make the predictions and calculate the validation loss\n",
    "\t\t\t\tpred = model(x)\n",
    "\t\t\t\ttotalValLoss += lossFn(pred, y.type(torch.float32).unsqueeze(1))\n",
    "\t\t\t\t# calculate the number of correct predictions\n",
    "\t\t\t\tvalCorrect += (torch.round(pred) == y).type(torch.float).mean().item()\n",
    "\t\n",
    "\t\t# calculate the average training and validation loss\n",
    "\t\tavgTrainLoss = totalTrainLoss / trainSteps\n",
    "\t\tavgValLoss = totalValLoss / valSteps\n",
    "\t\t\n",
    "\t\t# calculate the training and validation accuracy\n",
    "\t\tavgtrainCorrect = trainCorrect / len(trainloader)\n",
    "\t\tavgvalCorrect = valCorrect / len(valloader)\n",
    "\t\t\n",
    "\t\t# update our training history\n",
    "\t\ttrain_loss.append(avgTrainLoss.cpu().detach().numpy())\n",
    "\t\ttrain_acc.append(avgtrainCorrect)\n",
    "\t\tval_loss.append(avgValLoss.cpu().detach().numpy())\n",
    "\t\tval_acc.append(avgvalCorrect)\n",
    "\t\t\n",
    "\t\t# print the model training and validation information\n",
    "\t\tprint(\"[INFO] Epoch: {}/{}\".format(e + 1, num_epochs))\n",
    "\t\tprint(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(avgTrainLoss, avgtrainCorrect))\n",
    "\t\tprint(\"Valid loss: {:.6f}, Valid accuracy: {:.4f}\\n\".format(avgValLoss, avgvalCorrect))\n",
    "\n",
    "\t\t# early_stopping needs the validation loss to check if it has decresed, \n",
    "\t\t# and if it has, it will make a checkpoint of the current model\n",
    "\t\tearly_stopping(avgValLoss, model)\n",
    "        \n",
    "\t\tif early_stopping.early_stop:\n",
    "\t\t\tprint(\"Early stopping\")\n",
    "\t\t\tbreak\n",
    "\t\n",
    "\t# load the last checkpoint with the best model\n",
    "\tmodel.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\t\n",
    "\treturn  model, train_loss, train_acc, val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Epoch: 1/50\n",
      "Train loss: 0.701250, Train accuracy: 0.5156\n",
      "Valid loss: 0.716323, Valid accuracy: 0.5146\n",
      "\n",
      "Validation loss decreased (inf --> 0.716323).  Saving model ...\n",
      "[INFO] Epoch: 2/50\n",
      "Train loss: 0.672559, Train accuracy: 0.4917\n",
      "Valid loss: 0.582616, Valid accuracy: 0.7659\n",
      "\n",
      "Validation loss decreased (0.716323 --> 0.582616).  Saving model ...\n",
      "[INFO] Epoch: 3/50\n",
      "Train loss: 0.342422, Train accuracy: 0.5254\n",
      "Valid loss: 0.318296, Valid accuracy: 0.8668\n",
      "\n",
      "Validation loss decreased (0.582616 --> 0.318296).  Saving model ...\n",
      "[INFO] Epoch: 4/50\n",
      "Train loss: 0.177804, Train accuracy: 0.5238\n",
      "Valid loss: 0.198784, Valid accuracy: 0.9184\n",
      "\n",
      "Validation loss decreased (0.318296 --> 0.198784).  Saving model ...\n",
      "[INFO] Epoch: 5/50\n",
      "Train loss: 0.115631, Train accuracy: 0.5321\n",
      "Valid loss: 0.136663, Valid accuracy: 0.9413\n",
      "\n",
      "Validation loss decreased (0.198784 --> 0.136663).  Saving model ...\n",
      "[INFO] Epoch: 6/50\n",
      "Train loss: 0.048369, Train accuracy: 0.5309\n",
      "Valid loss: 0.174245, Valid accuracy: 0.9057\n",
      "\n",
      "EarlyStopping counter: 1 out of 7\n",
      "[INFO] Epoch: 7/50\n",
      "Train loss: 0.073617, Train accuracy: 0.5292\n",
      "Valid loss: 0.118789, Valid accuracy: 0.9431\n",
      "\n",
      "Validation loss decreased (0.136663 --> 0.118789).  Saving model ...\n",
      "[INFO] Epoch: 8/50\n",
      "Train loss: 0.037163, Train accuracy: 0.5312\n",
      "Valid loss: 0.110594, Valid accuracy: 0.9624\n",
      "\n",
      "Validation loss decreased (0.118789 --> 0.110594).  Saving model ...\n",
      "[INFO] Epoch: 9/50\n",
      "Train loss: 0.029681, Train accuracy: 0.5288\n",
      "Valid loss: 0.098899, Valid accuracy: 0.9668\n",
      "\n",
      "Validation loss decreased (0.110594 --> 0.098899).  Saving model ...\n",
      "[INFO] Epoch: 10/50\n",
      "Train loss: 0.031547, Train accuracy: 0.5324\n",
      "Valid loss: 0.079557, Valid accuracy: 0.9603\n",
      "\n",
      "Validation loss decreased (0.098899 --> 0.079557).  Saving model ...\n",
      "[INFO] Epoch: 11/50\n",
      "Train loss: 0.016869, Train accuracy: 0.5349\n",
      "Valid loss: 0.075119, Valid accuracy: 0.9621\n",
      "\n",
      "Validation loss decreased (0.079557 --> 0.075119).  Saving model ...\n",
      "[INFO] Epoch: 12/50\n",
      "Train loss: 0.031650, Train accuracy: 0.5280\n",
      "Valid loss: 0.080531, Valid accuracy: 0.9643\n",
      "\n",
      "EarlyStopping counter: 1 out of 7\n",
      "[INFO] Epoch: 13/50\n",
      "Train loss: 0.021117, Train accuracy: 0.5324\n",
      "Valid loss: 0.065415, Valid accuracy: 0.9642\n",
      "\n",
      "Validation loss decreased (0.075119 --> 0.065415).  Saving model ...\n",
      "[INFO] Epoch: 14/50\n",
      "Train loss: 0.076014, Train accuracy: 0.5373\n",
      "Valid loss: 0.332526, Valid accuracy: 0.8115\n",
      "\n",
      "EarlyStopping counter: 1 out of 7\n",
      "[INFO] Epoch: 15/50\n",
      "Train loss: 0.074576, Train accuracy: 0.5291\n",
      "Valid loss: 0.067115, Valid accuracy: 0.9643\n",
      "\n",
      "EarlyStopping counter: 2 out of 7\n",
      "[INFO] Epoch: 16/50\n",
      "Train loss: 0.019106, Train accuracy: 0.5318\n",
      "Valid loss: 0.105039, Valid accuracy: 0.9540\n",
      "\n",
      "EarlyStopping counter: 3 out of 7\n",
      "[INFO] Epoch: 17/50\n",
      "Train loss: 0.010273, Train accuracy: 0.5288\n",
      "Valid loss: 0.083668, Valid accuracy: 0.9665\n",
      "\n",
      "EarlyStopping counter: 4 out of 7\n",
      "[INFO] Epoch: 18/50\n",
      "Train loss: 0.008908, Train accuracy: 0.5327\n",
      "Valid loss: 0.071020, Valid accuracy: 0.9686\n",
      "\n",
      "EarlyStopping counter: 5 out of 7\n",
      "[INFO] Epoch: 19/50\n",
      "Train loss: 0.000503, Train accuracy: 0.5352\n",
      "Valid loss: 0.062099, Valid accuracy: 0.9728\n",
      "\n",
      "Validation loss decreased (0.065415 --> 0.062099).  Saving model ...\n",
      "[INFO] Epoch: 20/50\n",
      "Train loss: 0.000230, Train accuracy: 0.5326\n",
      "Valid loss: 0.077911, Valid accuracy: 0.9707\n",
      "\n",
      "EarlyStopping counter: 1 out of 7\n",
      "[INFO] Epoch: 21/50\n",
      "Train loss: 0.000170, Train accuracy: 0.5287\n",
      "Valid loss: 0.081430, Valid accuracy: 0.9686\n",
      "\n",
      "EarlyStopping counter: 2 out of 7\n",
      "[INFO] Epoch: 22/50\n",
      "Train loss: 0.000091, Train accuracy: 0.5308\n",
      "Valid loss: 0.080623, Valid accuracy: 0.9686\n",
      "\n",
      "EarlyStopping counter: 3 out of 7\n",
      "[INFO] Epoch: 23/50\n",
      "Train loss: 0.000057, Train accuracy: 0.5292\n",
      "Valid loss: 0.095496, Valid accuracy: 0.9686\n",
      "\n",
      "EarlyStopping counter: 4 out of 7\n",
      "[INFO] Epoch: 24/50\n",
      "Train loss: 0.000029, Train accuracy: 0.5341\n",
      "Valid loss: 0.095198, Valid accuracy: 0.9686\n",
      "\n",
      "EarlyStopping counter: 5 out of 7\n",
      "[INFO] Epoch: 25/50\n",
      "Train loss: 0.000808, Train accuracy: 0.5337\n",
      "Valid loss: 0.292661, Valid accuracy: 0.9411\n",
      "\n",
      "EarlyStopping counter: 6 out of 7\n",
      "[INFO] Epoch: 26/50\n",
      "Train loss: 0.081724, Train accuracy: 0.5262\n",
      "Valid loss: 0.071558, Valid accuracy: 0.9647\n",
      "\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "model, AvgTrainLoss, avgtrainCorrect, avgValLoss, avgvalCorrect = train_model(model, bs, patience, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The model stopped training after the 26th epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the loss as the network trained\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(AvgTrainLoss)+1),AvgTrainLoss, label='Training Loss')\n",
    "plt.plot(range(1,len(avgValLoss)+1),avgValLoss,label='Validation Loss')\n",
    "\n",
    "# find position of lowest validation loss\n",
    "minposs = avgValLoss.index(min(avgValLoss))+1 \n",
    "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0, 0.5) # consistent scale\n",
    "plt.xlim(0, len(AvgTrainLoss)+1) # consistent scale\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('loss_plot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] total time taken to train the model: 5053.38s\n"
     ]
    }
   ],
   "source": [
    "# finish measuring how long training took\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will now test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0356, Accuracy: 592/597 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, lossFn, testloader):\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  pred_list, true_list = [], []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for (x, y) in testloader:\n",
    "      if len(x.shape) == 3:\n",
    "        x = torch.unsqueeze(x,0)\n",
    "      out = model(x).flatten()\n",
    "      if type(x)!=type(y):\n",
    "        y=torch.Tensor([y])\n",
    "      test_loss += lossFn(out, y.type(torch.float32))\n",
    "      correct += torch.round(out).eq(y).sum()\n",
    "      pred_list.append(torch.round(out))\n",
    "      true_list.append(y.type(torch.float32))\n",
    "\n",
    "      # Print every 100 iterations\n",
    "      if (i + 1) % 100 == 0:\n",
    "        print(f\"Iteration {i+1}/{len(testloader)}\")\n",
    "      \n",
    "    test_loss /= len(testloader)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(testloader),\n",
    "            100. * correct / len(testloader)))\n",
    "    \n",
    "  return pred_list, true_list\n",
    "\n",
    "predictions, labels = test_model(model, lossFn, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99       287\n",
      "         1.0       1.00      0.99      0.99       310\n",
      "\n",
      "    accuracy                           0.99       597\n",
      "   macro avg       0.99      0.99      0.99       597\n",
      "weighted avg       0.99      0.99      0.99       597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate a classification report\n",
    "print(classification_report([i.item() for i in predictions], [i.item() for i in labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We got a F1-score of 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifying Sequence of Images\n",
    "\n",
    "##### In order to classify sequences of images, we first divide the files by name (ID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To write a list of file names\n",
    "\n",
    "#Define the path to the folder\n",
    "#for loop for folders inside all folders\n",
    "folder_path = \"images/training\"\n",
    "\n",
    "# Get all files\n",
    "all_files = []\n",
    "for fold in os.listdir(folder_path):\n",
    "    all_files.extend(os.listdir(os.path.join(folder_path, fold)))\n",
    "\n",
    "# Get the IDs\n",
    "all_files = pd.Series(all_files)\n",
    "unique_ids = all_files.str.split('_', n=1, expand=True)[0].unique()\n",
    "\n",
    "# Dictionary to store counts of files for each unique ID\n",
    "file_counts = {id_: 0 for id_ in unique_ids}\n",
    "\n",
    "# Count files for each unique ID\n",
    "for file_name in all_files:\n",
    "    file_id = file_name.split('_', 1)[0]\n",
    "    if file_id in file_counts:\n",
    "        file_counts[file_id] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will now train the model by iterating over each sequence (ID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ID: 0001, Count: 40\n",
      "Processing ID: 0002, Count: 31\n",
      "Processing ID: 0003, Count: 48\n",
      "Processing ID: 0004, Count: 46\n",
      "Processing ID: 0005, Count: 50\n",
      "Processing ID: 0006, Count: 41\n",
      "Processing ID: 0007, Count: 51\n",
      "Processing ID: 0008, Count: 48\n",
      "Processing ID: 0009, Count: 43\n",
      "Processing ID: 0010, Count: 48\n",
      "Processing ID: 0011, Count: 48\n",
      "Processing ID: 0012, Count: 17\n",
      "Processing ID: 0013, Count: 22\n",
      "Processing ID: 0014, Count: 12\n",
      "Processing ID: 0015, Count: 49\n",
      "Processing ID: 0016, Count: 44\n",
      "Processing ID: 0017, Count: 17\n",
      "Processing ID: 0018, Count: 21\n",
      "Processing ID: 0019, Count: 40\n",
      "Processing ID: 0020, Count: 31\n",
      "Processing ID: 0021, Count: 23\n",
      "Processing ID: 0022, Count: 16\n",
      "Processing ID: 0023, Count: 39\n",
      "Processing ID: 0024, Count: 30\n",
      "Processing ID: 0025, Count: 34\n",
      "Processing ID: 0026, Count: 36\n",
      "Processing ID: 0027, Count: 30\n",
      "Processing ID: 0028, Count: 53\n",
      "Processing ID: 0029, Count: 37\n",
      "Processing ID: 0030, Count: 52\n",
      "Processing ID: 0031, Count: 34\n",
      "Processing ID: 0032, Count: 32\n",
      "Processing ID: 0033, Count: 31\n",
      "Processing ID: 0034, Count: 34\n",
      "Processing ID: 0035, Count: 40\n",
      "Processing ID: 0036, Count: 36\n",
      "Processing ID: 0037, Count: 37\n",
      "Processing ID: 0038, Count: 56\n",
      "Processing ID: 0039, Count: 47\n",
      "Processing ID: 0040, Count: 41\n",
      "Processing ID: 0041, Count: 39\n",
      "Processing ID: 0042, Count: 46\n",
      "Processing ID: 0043, Count: 35\n",
      "Processing ID: 0044, Count: 49\n",
      "Processing ID: 0045, Count: 44\n",
      "Processing ID: 0046, Count: 38\n",
      "Processing ID: 0047, Count: 46\n",
      "Processing ID: 0048, Count: 46\n",
      "Processing ID: 0049, Count: 32\n",
      "Processing ID: 0050, Count: 39\n",
      "Processing ID: 0051, Count: 41\n",
      "Processing ID: 0052, Count: 40\n",
      "Processing ID: 0053, Count: 50\n",
      "Processing ID: 0054, Count: 42\n",
      "Processing ID: 0055, Count: 43\n",
      "Processing ID: 0056, Count: 38\n",
      "Processing ID: 0057, Count: 43\n",
      "Processing ID: 0058, Count: 46\n",
      "Processing ID: 0059, Count: 25\n",
      "Processing ID: 0060, Count: 43\n",
      "Processing ID: 0061, Count: 16\n",
      "Processing ID: 0062, Count: 22\n",
      "Processing ID: 0063, Count: 11\n",
      "Processing ID: 0064, Count: 10\n",
      "Processing ID: 0065, Count: 23\n"
     ]
    }
   ],
   "source": [
    "#calling our model\n",
    "seqmodel = Net()\n",
    "\n",
    "# Iterate over the items of the dictionary\n",
    "for id_, count in file_counts.items():\n",
    "    print(f'Processing ID: {id_}, Count: {count}')\n",
    "\n",
    "    # Create a DataLoader for the current ID\n",
    "    seq_data = datasets.ImageFolder('images/training', transform=transform, is_valid_file=file_screener)\n",
    "    seq_data.samples = [(sample, label) for sample, label in seq_data.samples if f'{id_}_' in sample]\n",
    "    seq_loader = DataLoader(seq_data, batch_size=1, shuffle=False)\n",
    "\n",
    "    # set the model in training mode\n",
    "    seqmodel.train()\n",
    "    # Iterate over the data loader\n",
    "    for images, labels in seq_loader:\n",
    "        opt.zero_grad()\n",
    "        outputs = seqmodel(images)\n",
    "        loss = lossFn(outputs, labels.unsqueeze(1).type(torch.float32))\n",
    "        loss.backward()\n",
    "        opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will now test the model over sequences of images. In order to test accuracy, if the maximum probability of a sequence exceeeds 0.5, the sequence will be labeled as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing for sequence of images.\n",
    "#To write a list of file names\n",
    "\n",
    "#Define the path to the folder\n",
    "#for loop for folders inside all folders\n",
    "folder_path_test = \"images/testing\"\n",
    "\n",
    "# Get all files\n",
    "test_files = []\n",
    "for fold in os.listdir(folder_path_test):\n",
    "    test_files.extend(os.listdir(os.path.join(folder_path_test, fold)))\n",
    "\n",
    "# Get the IDs\n",
    "test_files = pd.Series(test_files)\n",
    "test_unique_ids = test_files.str.split('_', n=1, expand=True)[0].unique()\n",
    "\n",
    "# Dictionary to store counts of files for each unique ID\n",
    "testfile_counts = {id_: 0 for id_ in test_unique_ids}\n",
    "\n",
    "# Count files for each unique ID\n",
    "for file_name in test_files:\n",
    "    test_file_id = file_name.split('_', 1)[0]\n",
    "    if test_file_id in testfile_counts:\n",
    "        testfile_counts[test_file_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Test ID: 0001\n",
      "Processing Test ID: 0002\n",
      "Processing Test ID: 0003\n",
      "Processing Test ID: 0004\n",
      "Processing Test ID: 0005\n",
      "Processing Test ID: 0006\n",
      "Processing Test ID: 0007\n",
      "Processing Test ID: 0008\n",
      "Processing Test ID: 0009\n",
      "Processing Test ID: 0010\n",
      "Processing Test ID: 0011\n",
      "Processing Test ID: 0012\n",
      "Processing Test ID: 0013\n",
      "Processing Test ID: 0014\n",
      "Processing Test ID: 0015\n",
      "Processing Test ID: 0016\n",
      "Processing Test ID: 0017\n",
      "Processing Test ID: 0018\n",
      "Processing Test ID: 0019\n",
      "Processing Test ID: 0020\n",
      "Processing Test ID: 0021\n",
      "Processing Test ID: 0022\n",
      "Processing Test ID: 0024\n",
      "Processing Test ID: 0026\n",
      "Processing Test ID: 0027\n",
      "Processing Test ID: 0028\n",
      "Processing Test ID: 0029\n",
      "Processing Test ID: 0030\n",
      "Processing Test ID: 0031\n",
      "Processing Test ID: 0032\n",
      "Processing Test ID: 0033\n",
      "Processing Test ID: 0034\n",
      "Processing Test ID: 0035\n",
      "Processing Test ID: 0036\n",
      "Processing Test ID: 0037\n",
      "Processing Test ID: 0038\n",
      "Processing Test ID: 0039\n",
      "Processing Test ID: 0040\n",
      "Processing Test ID: 0041\n",
      "Processing Test ID: 0042\n",
      "Processing Test ID: 0043\n",
      "Processing Test ID: 0044\n",
      "Processing Test ID: 0045\n",
      "Processing Test ID: 0046\n",
      "Processing Test ID: 0047\n",
      "Processing Test ID: 0048\n",
      "Processing Test ID: 0049\n",
      "Processing Test ID: 0050\n",
      "Processing Test ID: 0051\n",
      "Processing Test ID: 0052\n",
      "Processing Test ID: 0053\n",
      "Processing Test ID: 0054\n",
      "Processing Test ID: 0055\n",
      "Processing Test ID: 0056\n",
      "Processing Test ID: 0057\n",
      "Processing Test ID: 0058\n",
      "Processing Test ID: 0059\n",
      "Processing Test ID: 0060\n",
      "Processing Test ID: 0061\n",
      "Processing Test ID: 0062\n",
      "Processing Test ID: 0063\n",
      "Processing Test ID: 0064\n",
      "Processing Test ID: 0065\n",
      "Processing Test ID: 0023\n",
      "Processing Test ID: 0025\n",
      "Overall Test Accuracy: 80.00%\n",
      "Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.80      1.00      0.89        52\n",
      "\n",
      "    accuracy                           0.80        65\n",
      "   macro avg       0.40      0.50      0.44        65\n",
      "weighted avg       0.64      0.80      0.71        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to collect true and predicted labels for all IDs\n",
    "all_true_labels = []\n",
    "all_predicted_labels = []\n",
    "\n",
    "# Iterate over each unique ID\n",
    "for id_ in test_unique_ids:\n",
    "    print(f'Processing Test ID: {id_}')\n",
    "\n",
    "    # Create a DataLoader for the current ID\n",
    "    test_seq_data = datasets.ImageFolder('images/testing', transform=transform, is_valid_file=file_screener)\n",
    "    test_seq_data.samples = [(sample, label) for sample, label in test_seq_data.samples if f'{id_}_' in sample]\n",
    "    test_seq_loader = DataLoader(test_seq_data, batch_size=1, shuffle=False)\n",
    "\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Iterate over the DataLoader for the current ID\n",
    "    for images, labels in test_seq_loader:\n",
    "        with torch.no_grad():\n",
    "            if len(images.shape) == 3:\n",
    "                images = torch.unsqueeze(images, 0)\n",
    "            outputs = seqmodel(images).flatten()\n",
    "\n",
    "            # Append true and predicted labels\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(torch.round(outputs).cpu().numpy())\n",
    "\n",
    "    # Calculate the predicted label as the maximum probability\n",
    "    predicted_label = 1 if np.max(outputs.numpy()) > 0.5 else 0\n",
    "    \n",
    "    # Append the predicted label for the current ID\n",
    "    all_predicted_labels.append(predicted_label)\n",
    "\n",
    "    # Check if there is at least one positive label in the ground truth labels\n",
    "    true_label = 1 if np.sum(true_labels) > 0 else 0\n",
    "\n",
    "    # Append the true label for the current ID\n",
    "    all_true_labels.append(true_label)\n",
    "\n",
    "# Convert the lists of true and predicted labels to numpy arrays\n",
    "all_true_labels = np.array(all_true_labels)\n",
    "all_predicted_labels = np.array(all_predicted_labels)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = np.sum(all_true_labels == all_predicted_labels) / len(all_true_labels) * 100\n",
    "\n",
    "# Print the overall accuracy\n",
    "print(f'Overall Test Accuracy: {overall_accuracy:.2f}%')\n",
    "\n",
    "# Generate and print the overall classification report\n",
    "overall_report = classification_report(all_true_labels, all_predicted_labels)\n",
    "print(\"Overall Classification Report:\")\n",
    "print(overall_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The overall test accuracy for the sequences of images was found to be 80%.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "##### In this project, we've successfully trained a conventional CNN model achieving a 99% accuracy in distinguishing between flipped and non-flipped images, and an 80% accuracy in categorizing sequences of images. The insights gained from image and video analyses conducted in this project hold significant relevance across a wide range of image classification tasks, offering valuable contributions to various domains requiring such classification capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
